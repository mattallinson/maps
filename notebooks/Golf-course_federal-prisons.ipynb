{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prison_data_getter():\n",
    "    '''gets all the data about federal prisons on wikipedia and then scrapes their location\n",
    "    saving this data as a csv to enable manual addition of the ones that, for whatever reason\n",
    "    don't have proper location data on wikipedia.\n",
    "    '''\n",
    "    \n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_United_States_federal_prisons\"\n",
    "    wiki = 'https://en.wikipedia.org'\n",
    "    api = 'https://en.wikipedia.org/w/api.php'\n",
    "\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "\n",
    "    tables = soup.find_all('table')[:4]\n",
    "\n",
    "    prisons = []\n",
    "    for table in tables:\n",
    "        prisons += [{'name': p['title'],\n",
    "                     'link':wiki+p['href']}\n",
    "                     for p in table.find_all('a')]\n",
    "    print(prisons[:5])\n",
    "\n",
    "    for prison in prisons:\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"prop\": \"coordinates\",\n",
    "            \"titles\": prison['name'],\n",
    "            \"formatversion\": \"2\"\n",
    "        }\n",
    "\n",
    "        r = requests.get(api, params=params)\n",
    "        prison_data = r.json()['query']['pages'][0]\n",
    "\n",
    "        if 'coordinates' in prison_data.keys():\n",
    "            prison['lat'] = prison_data['coordinates'][0]['lat']\n",
    "            prison['lon'] = prison_data['coordinates'][0]['lon']\n",
    "\n",
    "    df = pd.DataFrame(prisons).set_index('name')\n",
    "\n",
    "    df.to_csv('prisons.csv')\n",
    "    \n",
    "def prison_geojson_maker():\n",
    "    '''turns the csv created above into a gsojson with the locations saved as points\n",
    "    '''\n",
    "    df = pd.read_csv('prisons.csv').set_index('name')\n",
    "    gdf = gpd.GeoDataFrame(df,\n",
    "        crs={'init': 'epsg:4326'},\n",
    "        geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "\n",
    "    gdf.to_file(\"../data/federal_prisons.geojson\", driver='GeoJSON')\n",
    "    \n",
    "    \n",
    "# To generate the database uncomment the below lines. After running the first line you \n",
    "# need to open the csv file and manually add the lat and lon 4 or 5 prisons that for\n",
    "# whatever reasons don't download properly, but they're easily gettable from google \n",
    "\n",
    "\n",
    "# prison_data_getter()\n",
    "# prison_geojson_maker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prisons = gpd.read_file(\"../data/federal_prisons.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-76.927"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
